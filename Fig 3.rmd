**Load functions and library from source.Rmd**


**Specify the organism of the data set**

```{r}
organism = "human" # choose "mouse" or "human"
```


**Specify the project directory here:**

```{r, warning=F}
dir <- "E:/RNA-Seq/Wataru_COPD/GitHub/"

# creating output directories (if not already existing):
dir.create(file.path(dir, "Analysis", "Tables"), recursive = T)
dir.create(file.path(dir, "Analysis", "Plots"), recursive = T)
```

# 3. Data Import

## Load gene annotation

This gene annotation file will be used 
  1) to map the Ensembl transcript IDs to Ensembl gene IDs during the tximport function and 
  2) annotate the Ensembl IDs with additional information such as gene symbol or type.
  
For consistency, this file should have been produced from the .gtf file used for building the kallisto index. It needs to consist of four columns: Gene ENSEMBL ID, Transcript ID, Gene Symbol, Gene Type.

```{r gene annotation import}
# Specify the filename of your gene annotation file here: 
annotation_filename <- "ID2SYMBOL_gencode_v27_transcript.txt"

tx_annotation <- read.delim(file.path(dir, "Data", annotation_filename), 
                         header = F , 
                         stringsAsFactors = F,
                         col.names = c("GENEID", "TXNAME", "SYMBOL", "GENETYPE"))
```

## Load gene set annotation
```{r}
# Transcrption Factors
# read mouse TF list
TFlist_mm <-read.csv(file.path(dir, "Data/GMTfiles/20180317_TFlist_mouse_TFdb_riken.csv", sep=""), 
                       stringsAsFactors = FALSE, 
                       header = FALSE)[,1]
# read human TF list
TFlist_hs <- read.csv(file.path(dir, "Data/GMTfiles/20180317_TFlist_human_Lambert_Cell2018.csv", sep=""),
                       stringsAsFactors = FALSE, 
                       header = FALSE)[,1]
# GO
GO_mm <- read.delim(file.path(dir, "Data/GMTfiles/GO_mm38p12_ensembl181121.txt"),header=TRUE,stringsAsFactors = FALSE,quote="")
GO_hs <- read.delim(file.path(dir, "Data/GMTfiles/GO_hg38p12_ensembl181121.txt"),header=TRUE,stringsAsFactors = FALSE,quote="")
# KEGG
KEGG_mm <- read.delim(file.path(dir, "Data/GMTfiles/KEGG_mm10_clusterProfiler181121.txt"),header=TRUE,stringsAsFactors = FALSE)
KEGG_hs <- read.delim(file.path(dir, "Data/GMTfiles/KEGG_hg38_clusterProfiler181121.txt"),header=TRUE,stringsAsFactors = FALSE)
# MiSigDB gene sets
hallmark_genes <- clusterProfiler::read.gmt(file.path(dir, "Data/GMTfiles/h.all.v6.2.entrez.gmt"))
cannonicalPathway_genes <- clusterProfiler::read.gmt(file.path(dir, "Data/GMTfiles/c2.cp.v6.2.entrez.gmt"))
immuno_genes <- clusterProfiler::read.gmt(file.path(dir, "Data/GMTfiles/c7.all.v6.2.entrez.gmt"))
motifs <- clusterProfiler::read.gmt(file.path(dir, "Data/GMTfiles/c3.all.v6.2.entrez.gmt"))
```

## Load sample table

Now, we read a table containing all available metainformation for the samples. This table needs to be prepared beforehand from information on the sequencing tracker or provided by the experimental partners.

```{r sample table import}
sample_table <- read.delim(file.path(dir, "Data", "sample_table.txt"))
rownames(sample_table) <- sample_table$ID
sample_table
```

### Format sample table

For the correct order of the samples in later plots, we define the column of our sample table that contains the information of interest and reorder its factor levels.

```{r colour definitions}
## Add columns with factors for comparisons in model
sample_table$Genotype_Age <- factor(sample_table$conditions,
                                   levels = c("COPD", "Sarcoidosis", "Control", "Asthma"))

sample_table$smoking <- factor(sample_table$smoking,
                                   levels = unique(sample_table$smoking))


# order according to factor of interest
sample_table <- sample_table[order(sample_table$conditions),]

# define factor for order of samples in plotting 
plot_order <- "conditions"
```

### Colour scheme customization

Define you colour schemes according to your data set and your variables!

For hex colors use: https://www.color-hex.com

```{r}
# Genotype
col_conditions <- c("#FFEDA0", "#FEB24C")
names(col_conditions) <- c("COPD", "Control") 
# Age
# col_age = c("#FFEDA0", "#FEB24C", "#F03B20")
# names(col_age) <- c("4mo", "8mo", "12mo")
# # Sex
# col_sex <- c("##66C3D0", "#008DD2")
# names(col_sex) <- c("f", "m")
# # merged: Genotype and Age
col_condition <- c(brewer.pal(3, "Oranges"))
names(col_condition) <- c("Control", "COPD_2", "COPD_3_4")

# combine color code into list
ann_colors <- list(conditions = col_conditions,condition = col_condition)
```


# 4. TXimport

A new and recommended pipeline for RNA-seq analysis is to use fast transcript abundance quantifiers, such as kallisto or Salmon, upstream of DESeq2, and then to create gene-level count matrices for use with DESeq2 by importing the quantification data using the tximport package.

We use tximport and DESeq2 based on the gene-level estimated counts from Kallisto (Bray, Pimentel, Melsted, Pachter 2016). 

Some advantages of using this methods for transcript abundance estimation are: 

  * this approach corrects for potential changes in gene length across samples (e.g. from differential isoform usage) (Trapnell et al. 2013), 
  * some of these methods (Salmon, Sailfish, kallisto) are substantially faster and require less memory and disk usage compared to alignment-based methods that require creation and storage of BAM files, and,
  * it is possible to avoid discarding those fragments that can align to multiple genes with homologous sequence, thus increasing sensitivity (Robert and Watson 2015).

Full details on the motivation and methods for importing transcript level abundance and count estimates, summarizing to gene-level count matrices and producing an offset which corrects for potential changes in average transcript length across samples are described in (Soneson, Love, and Robinson 2015). Note that the tximport-to-DESeq2 approach uses estimated gene counts from the transcript abundance quantifiers, but not normalized counts.

TXimport imports transcript-level abundance, estimated counts and transcript lengths, and summarizes these into matrices for use with downstream statistical analysis packages such as edgeR, DESeq2, limma-voom. 
Average transcript length, weighted by sample-specific transcript abundance estimates, is provided 
as a matrix, which is then used as an offset for different expression of gene-level counts.

```{r kallisto import}
# Define path where the Kallisto files are stored
files <- paste(dir, "/Data/output/kallisto/kallisto/", sample_table$ID, "/abundance.h5", sep = "")
# Naming the entries in the vector assures correct column names in the expression tables
names(files) <- sample_table$ID
# Import samples and perform the distribution of transcripts to genes
txi_kallisto <- tximport(files, 
                         type="kallisto", 
                         tx2gene=tx_annotation[,2:1])

```

# 5. Building the DESeqDataSet

The object class used by the DESeq2 package to store the read counts and the intermediate estimated quantities during statistical analysis is the DESeqDataSet, which will usually be represented in the code here as an object called "dds". 

A DESeqDataSet object must have an associated design formula. The design formula expresses the variables which will be used in modeling. The formula should be a tilde (~) followed by the variables with plus signs between them (it will be coerced into a formula if it is not already). The design can be changed later, however then all differential analysis steps should be repeated, as the design formula is used to estimate the dispersions and to estimate the log2 fold changes of the model.

```{r DESeqDatasetFromTXimport}
dds_txi <- DESeqDataSetFromTximport(txi = txi_kallisto, 
                                    colData = sample_table,
                                    design = ~ condition)
```

## Pre-filtering

While it is not necessary to pre-filter low count genes before running the DESeq2 functions, there are two reasons which make pre-filtering useful: 
  * by removing rows in which there are very few reads, we reduce the memory size of the dds data object, and 
  * we increase the speed of the transformation and testing functions within DESeq2. 

Here, we perform a minimal pre-filtering to keep only rows that have at least 10 reads total. 

*Note that more strict filtering to increase power is automatically applied via independent filtering or independent hypothesis weighting on the mean of normalized counts within the results function.*

```{r pre-filtering}
genes_to_keep <- rowSums(counts(dds_txi)) >= 10
dds <- dds_txi[genes_to_keep,]
```

**Number of genes after filtering is:** `r sum(genes_to_keep) `

## DESeq calculations

**DESeq2:** Estimate variance-mean dependence (2) in count data from high-throughput sequencing assays and test for differential expression based on a model using the negative binomial distribution (1).

1) In inferential testing a distributional assumption is needed because we want to estimate the probability of extreme events just appearing by chance (e.g. large fold change) from limited replicates. The test statistic of ANOVA (or t-test) follows a Student's t distribution, a specific case of the normal distribution. However, counts, as produced in RNA-seq experiments, cannot be normally distributed by definition(you can't have -3 counts, or 12.2 counts). Two distributions for count based data are Poisson, which presumes that the variance and mean are equal, or negative binomial, a.k.a. Gamma-Poisson, which does not. The spread of values among biological replicates is more than given by the one parameter Poisson distribution and it seems to be captured by the two parameter (mean & variance) NB sufficiently well.

2) Information sharing across genes for variance estimation:  
In order to test the differential expression of a gene, we need to estimate its mean and variance for the underlying negative binomial distribution. Inferential methods that treat each gene separately suffer from the high uncertainty of within-group variance estimates. However, this limitation can be overcome by pooling information across genes, specifically, by exploiting assumptions about the similarity of the variances of different genes measured in the same experiment . DESeq2 detects and corrects dispersion estimates through modeling of the dependence of the dispersion on the average mean over all samples.

The standard differential expression analysis steps are wrapped into a single function, DESeq(). The estimation steps performed by this function are described in the manual page for ?DESeq and in the Methods section of the DESeq2 publication (Love, Huber, and Anders 2014).

This function performs a default analysis through the steps:

  1. Estimation of size factors: estimateSizeFactors

  2. Estimation of dispersion: estimateDispersions

  3. Negative Binomial GLM fitting and Wald statistics: nbinomWaldTest

For complete details on each step, see the manual pages of the respective functions. 

```{r DESeq calculation}
dds <- DESeq(dds)
```

## Normalized count table  

For inspection of the normalized data, we write the normalized counts into a data.frame called "norm_anno".

```{r gene annotation}
norm_anno <- as.data.frame(counts(dds, normalized=T))
norm_anno$GENEID <- row.names(norm_anno)

# add gene annotation extracted from the gtf file
gene_annotation <- tx_annotation[!duplicated(tx_annotation$GENEID),c("GENEID", "SYMBOL", "GENETYPE")]
gene_annotation <- gene_annotation[match(rownames(norm_anno), gene_annotation$GENEID),]

# check if row names of the normalized table and the gene annotation match perfectly
all(rownames(norm_anno) == gene_annotation$GENEID)

# add additional gene annotation downloaded from biomart
biomart <- read.delim(file.path(dir, "Data", "biomart_180914.txt"), stringsAsFactors = FALSE)
idx <- match(unlist(lapply(strsplit(gene_annotation$GENEID, split = "[.]"), `[[`, 1)), biomart$Gene.stable.ID)
gene_annotation$DESCRIPTION <- biomart$Gene.description[idx]
gene_annotation$CHR <- biomart$Chromosome.scaffold.name[idx]

# merge expression table and annotation
norm_anno <- merge(norm_anno,
                   gene_annotation,
                   by = "GENEID")
rownames(norm_anno) <- norm_anno$GENEID

norm_anno[1:3,c(1:2, (ncol(norm_anno)-5):ncol(norm_anno))]
```

## Variance stabilizing transformation

In order to test for differential expression, we operate on raw counts and use discrete distributions. However for other downstream analyses - e.g. for visualization or clustering - it might be useful to work with transformed versions of the count data.  

Maybe the most obvious choice of transformation is the logarithm. Since count values for a gene can be zero in some conditions (and non-zero in others), some advocate the use of pseudocounts, i.e. transformations of the form: y=log2(n+n0) where n represents the count values and n0 is a positive constant.

DESeq2 has two alternative approaches that offer more theoretical justification and a rational way of choosing parameters equivalent to n0 above. One makes use of the concept of variance stabilizing transformations (VST) (Tibshirani 1988; Huber et al. 2003; Anders and Huber 2010), and the other is the regularized logarithm or rlog, which incorporates a prior on the sample differences (Love, Huber, and Anders 2014). Both transformations produce transformed data on the log2 scale which has been normalized with respect to library size or other normalization factors.

The point of these two transformations, the VST and the rlog, is to remove the dependence of the variance on the mean, particularly the high variance of the logarithm of count data when the mean is low. Both VST and rlog use the experiment-wide trend of variance over mean, in order to transform the data to remove the experiment-wide trend. Note that we do not require or desire that all the genes have exactly the same variance after transformation. Indeed, in a figure below, you will see that after the transformations the genes with the same mean do not have exactly the same standard deviations, but that the experiment-wide trend has flattened. It is those genes with row variance above the trend which will allow us to cluster samples into interesting groups.

The two functions, vst and rlog have an argument blind, for whether the transformation should be blind to the sample information specified by the design formula. When blind equals TRUE (the default), the functions will re-estimate the dispersions using only an intercept. **This setting should be used in order to compare samples in a manner wholly unbiased by the information about experimental groups, for example to perform sample QA (quality assurance) as demonstrated below.**

However, blind dispersion estimation is not the appropriate choice if one expects that many or the majority of genes (rows) will have large differences in counts which are explainable by the experimental design, and one wishes to transform the data for downstream analysis. In this case, using blind dispersion estimation will lead to large estimates of dispersion, as it attributes differences due to experimental design as unwanted noise, and will result in overly shrinking the transformed values towards each other. By setting blind to FALSE, the dispersions already estimated will be used to perform transformations, or if not present, they will be estimated using the current design formula. Note that only the fitted dispersion estimates from mean-dispersion trend line are used in the transformation (the global dependence of dispersion on mean for the entire experiment). So setting blind to FALSE is still for the most part not using the information about which samples were in which experimental group in applying the transformation.

```{r varStab}
# Please choose to use rlog or VST for the transformation: rlog is recommended for less than 30 samples, vst for more than 30 samples for the sake of computing time

dds_vst <- rlog(dds, blind = TRUE)

# dds_vst <- vst(dds, blind = TRUE)
```
## Hierarchical Clustering of most variable genes {.tabset .tabset-fade}

```{r, echo=TRUE}
# define variable genes
rv = genefilter::rowVars(assay(dds_vst))
q75 = quantile(rowVars(assay(dds_vst)), .75)
q75_names = names(which(rv > q75))

```

###  clustered Columns & Rows
```{r, echo=TRUE, message=FALSE, results='hide', fig.height=5, fig.width=6}
plotHeatmap(geneset = q75_names,
                title = "Heatmap of all most variable genes",
                show_rownames = FALSE,
                cluster_cols = TRUE)

```

## Sample-to-Sample correlation & dcluster_cols = FAListance {.tabset .tabset-fade}

### Correlation

```{r, fig.height=10, fig.width=12}
# Correlation based on variance-stabilized counts
sampleCor <- as.matrix(cor(assay(dds_vst), use="all.obs", method="pearson"))
rownames(sampleCor)<- sample_table$ID
colnames(sampleCor)<- sample_table$ID

pheatmap(sampleCor,
         main="Sample Correlation based on variance-stabilized counts",
         annotation_row = plot_annotation,
         annotation_col = plot_annotation,
         annotation_colors = ann_colors,
         cluster_rows = F,
         cluster_cols = F,
         fontsize = 8)
```

### Distance  
This function computes and returns the euclidean distance matrix between the rows of a data matrix, the samples in our case. 

```{r, fig.height=10, fig.width=12}
# Sample Distances based on variance-stabilized counts
sampleDist <- as.matrix(dist(t(assay(dds_vst))))
rownames(sampleDist)<- sample_table$ID
colnames(sampleDist)<- sample_table$ID

pheatmap(sampleDist,
         clustering_distance_rows = dist(t(assay(dds_vst))),
         clustering_distance_cols = dist(t(assay(dds_vst))), 
         main="Sample distances based on variance-stabilized counts per sample",
         annotation_row = plot_annotation, 
         annotation_col = plot_annotation,
         annotation_colors = ann_colors,
         fontsize = 8)
```

## Principle Component Analysis 

Related to the distance matrix is the PCA plot, which shows the samples in the 2D plane spanned by two principal components. This type of plot is useful for visualizing the overall effect of experimental covariates and batch effects.

Principal component analysis (PCA) simplifies the complexity in high-dimensional data while retaining trends and patterns. It does this by transforming the data into fewer dimensions, which act as summaries of features. High-dimensional data are very common in biology and arise when multiple features, such as expression of many genes, are measured for each sample. This type of data presents several challenges that PCA mitigates: computational expense and an increased error rate due to multiple test correction when testing each feature for association with an outcome. PCA is an unsupervised learning method and is similar to clustering1-it finds patterns without reference to prior knowledge about whether the samples come from different treatment groups or have phenotypic differences.

To understand the basics of PCA, please watch: https://www.youtube.com/watch?v=_UVHneBUBW0

## SVA: Unknown batch effects

In case your samples do not cluster according to the condition of biological interested, but you observe distinct clustering according to an unknown latent variable, you may want to try identifying this "hidden"" batch variable using surrogate variable analysis (SVA). 

The SVA package helps to define the variance in the data set that is not explained by your variables of interest and tries to model the respective surrogate variables. These surrogate variables can be included as factors in your DESeq2 model. (http://master.bioconductor.org/packages/release/workflows/html/rnaseqGene.html#removing-hidden-batch-effects; http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.0030161)

The goal of the sva is to remove all unwanted sources of variation while protecting the contrasts due to the primary variables. This leads to the identification of features that are consistently different between groups, removing all common sources of latent variation. In some cases, the latent variables may be important sources of biological vari-
ability. If the goal of the analysis is to identify heterogeneity in one or more subgroups, the sva function may not be appropriate.  

The first step in using the sva package is to properly format the data and create appropriate model matrices. The data should be a matrix with features (genes, transcripts, voxels) in the rows and samples in the columns. Below we obtain a matrix of normalized counts for which the average count across samples is larger than 1. This is the typical genes by samples matrix found in gene expression analyses. The sva package assumes there are two types of variables that are being considered: (1) adjustment variables and (2) variables of interest. For example, in a gene expression study the variable of interest might an indicator of cancer versus control. The adjustment variables could be the age of the patients, the sex of the patients, and a variable like the date the arrays were processed.

Two model matrices must be made: the "full model" and the "null model". The null model is a model matrix that includes terms for all of the adjustment variables but not the variables of interest. The full model includes terms for both the adjustment variables and the variables of interest. The assumption is that you will be trying to analyze the association between the variables of interest and gene expression, adjusting for the adjustment variables. The model matrices can be created using the model.matrix() function.

After the model matrices have been created, we can apply the svaseq function to estimate batch and other artifacts. 

The svaseq function performs two different steps. First it identifies the number of latent factors that need to be estimated. If the sva function is called without the n.sv argument specified, the number of factors will be estimated for you. If you prefer a specific number of SVs, you can set the n.sv parameter accordingly.

```{r}
# Format and filter the input
dat <- counts(dds, normalized=TRUE)
idx <- rowMeans(dat) > 1
dat <- dat[idx,]

# Create the full model matrix - including both the adjustment variables and the variable of interest.  In this case we only have one variable of interest called Genotype_Age.
mod  <- model.matrix(~ condition, colData(dds))

# The null model contains only the adjustment variables. Since we are not adjusting for any other variables in this analysis, only an intercept is included in the model.
mod0 <- model.matrix(~ 1, colData(dds))
```

Apply the svaseq() function to estimate the surrogate variables:

The svaseq function returns a list with four components, sv, pprob.gam, pprob.b, n.sv:

sv is a matrix whose columns correspond to the estimated surrogate variables. They can be used in downstream analyses as described below. 
pprob.gam is the posterior probability that each gene is associated with one or more latent variables.
pprob.b is the posterior probability that each gene is associated with the variables of interest.
n.sv is the number of surrogate variables estimated by the sva.


```{r}
svseq <- svaseq(dat,
               mod,
               mod0)

svseq$sv
```

You can display whether the calculated SV correlate with any of your known covariates by changing dds$condition to the column of your sample_table that you are interested in.
```{r, fig.width=8, fig.height=10}

pdf("rplot.pdf", width = 8, height = 10) 
par(mfrow = c(5, ncol(svseq$sv)))

condition ="run"
for (i in 1:ncol(svseq$sv)) {
  stripchart(svseq$sv[, i] ~ dds[[condition]], vertical = TRUE, main = paste0("SV", i," - ",condition))
  abline(h = 0)
}

condition ="stage"
for (i in 1:ncol(svseq$sv)) {
  stripchart(svseq$sv[, i] ~ dds[[condition]], vertical = TRUE, main = paste0("SV", i," - ",condition))
  abline(h = 0)
}

condition ="sex"
for (i in 1:ncol(svseq$sv)) {
  stripchart(svseq$sv[, i] ~ dds[[condition]], vertical = TRUE, main = paste0("SV", i," - ",condition))
  abline(h = 0)
}

condition ="age"
for (i in 1:ncol(svseq$sv)) {
  stripchart(svseq$sv[, i] ~ dds[[condition]], vertical = TRUE, main = paste0("SV", i," - ",condition))
  abline(h = 0)
}

condition ="smoking"
for (i in 1:ncol(svseq$sv)) {
  stripchart(svseq$sv[, i] ~ dds[[condition]], vertical = TRUE, main = paste0("SV", i," - ",condition))
  abline(h = 0)
}
dev.off()
```


Add surrogate variables to annotation table to re-analyse the data including the surrogate variables in the analysis.

```{r}
for (i in 1:ncol(svseq$sv)) {
  sample_table[[paste0("SV",i)]]<- svseq$sv[,i]
}
```


Again, we can check in a PCA what an influence removing the SVs has on the clustering of the samples.

```{r}

removedbatch_dds_vst <- limmaBatchEffectRemoval(input=dds_vst,
                                                modelfactor = "condition",
                                                batchfactor = c("SV1","SV2","SV3","SV4","SV5"),
                                                batchfactor_2 = NULL)





plotPCA(pca_input = removedbatch_dds_vst,
         ntop="all",
         xPC=1,
         yPC=2,
         color="condition",
         anno_colour = "NULL",
         point_size=5,
         shape = "run",
         title="PCA of batch-corrected counts SVA5")




removedbatch_anno_log2<-removedbatch_dds_vst
removedbatch_anno_log2<-merge(removedbatch_anno_log2,norm_anno[,c("GENEID","SYMBOL","GENETYPE","DESCRIPTION","CHR")],by="row.names")
rownames(removedbatch_anno_log2)<-removedbatch_anno_log2$Row.names
removedbatch_anno_log2$Row.names<-NULL


removedbatch_anno<-removedbatch_dds_vst
removedbatch_anno<-2^removedbatch_anno
removedbatch_anno<-merge(removedbatch_anno,norm_anno[,c("GENEID","SYMBOL","GENETYPE","DESCRIPTION","CHR")],by="row.names")
rownames(removedbatch_anno)<-removedbatch_anno$Row.names
removedbatch_anno$Row.names<-NULL



```

## Include batch effect variables into DESeq2 model

In case you want to include the observed batch variables in your DESeq2 model, no matter if known covariates or surrogate variables, you can add these to your design formlua in front of the condition of interest and recalculate your dds object.
In the following expample we will include a Sex and three SVs as batch effects.

**ATTENTION: Skip this chunk, if you do not want to include any batch variables!**

```{r}
ddssva <- dds
ddssva$SV1 <- svseq$sv[,1]
ddssva$SV2 <- svseq$sv[,2]
ddssva$SV3 <- svseq$sv[,3]
ddssva$SV4 <- svseq$sv[,4]
ddssva$SV5 <- svseq$sv[,5]
design(ddssva) <- ~ SV1 + SV2 + SV3 + SV4 + SV5 + condition

dds <- DESeq(ddssva)
```

# 8. Differential Expression Analysis

After the DESeq() function performs the standard differential expression analysis steps, DESeq2's results() function can extract a result table from the DESeqDataSet giving base means across samples, log2 fold changes, standard errors, test statistics, p-values and adjusted p-values.

We have written a function called DEAnalysis() that runs DESeq2's results() and the lfcShrink() function with specified parameters on a set of pre-defined comparisons and returns a single DEresults object containing the respective result tables together with additional lists of the significant DE genes and the number of DE genes found.

The parameters of the DEAnalysis function are: 

  1) condition: specify the condition that you are testing, e.g. treatment or genotype. This value must correspond to the column in the colData listing the factors you are comparing and the design formula. 

  2) alpha:  a significance cutoff used for optimizing the independent filtering.(default= 0.05)
  
  3) lfcThreshold: a non-negative value which specifies a log2 fold change threshold. The default value is 0, corresponding to a test that the log2 fold changes are equal to zero. (default = 0)
  
  4) sigFC: post testing significance criteria as a non-negative, non-log transformed FC cutoff (default = 2)
  
  5) multiple_testing: By default independent hypothesis weighting will be used as the multiple testing method (https://bioconductor.org/packages/3.7/bioc/vignettes/IHW/inst/doc/introduction_to_ihw.html). However, you can also edit the multiple testing method by setting the multiple_testing parameter to "holm", "hochberg", "hommel", "bonferroni", "BH", "BY",or "fdr", which will perform independent filtering and p-value adjustment according to the specified method. (default = "IHW")
  
  6) shrinkage: After calculating differential expression statistics, we can perform a so-called log2 fold change shrinkage. This shrinkage of effect size (LFC estimates) is useful for visualization and ranking of genes, as it removes the noise associated with log2 fold changes from low count genes without requiring arbitrary filtering thresholds. To shrink the LFC, set shrinkage = TRUE to pass the dds object to the function lfcShrink.  (default = TRUE)

  7) shrinkType: The options for the shrinkage type are:

    * "normal" is the the original DESeq2 shrinkage estimator, an adaptive Normal distribution as prior.This is currently the default, although the default will likely change to apeglm in the October 2018 release given apeglm's superior           performance.

    * "apeglm" is the adaptive t prior shrinkage estimator from the apeglm package (Zhu, Ibrahim, and Love 2018).

    * "ashr" is the adaptive shrinkage estimator from the ashr package (Stephens 2016). Here DESeq2 uses the ashr option to fit a mixture of Normal distributions to form the prior, with method="shrinkage".


## Define relevant comparisons

Define your comparisons in a data.frame with "comparison" in the first column and "control" in the second column.

comparison | control
-----------|----------
tg_4mo     | wt_4mo
tg_8mo     | wt_8mo
tg_12mo    | wt_12mo

```{r}
comparison_table<-data.frame(comparison = c("COPD_2","COPD_3_4","COPD_2"),
                             control = c("Control","Control","COPD_3_4"))
```


## Perform Differential Expression Testing

```{r}
DEresults <- DEAnalysis(condition = "condition",
                        alpha=0.5,
                        lfcThreshold= 0,
                        sigFC = 1.5,
                        multiple_testing="IHW",
                        shrinkage = TRUE,
                        shrinkType="normal")

```

### Summary of DE genes

We use a for loop to print the number of significantly up- and down-regulated genes over all comparisons.

```{r}
DEcounts <- NULL

for(i in 1:nrow(comparison_table)){
  tmp <- unlist(DEresults[[1+i]]@Number_DE_genes)
  DEcounts <- rbind(DEcounts, tmp)
}


DEcounts

DEcounts_all_m$condi <- factor(DEcounts_all_m$condi, levels = c("COPD_2_vs_Control","COPD_3_4_vs_Control","COPD_2_vs_COPD_3_4"))


ggplot(data=DEcounts_all_m, aes(x=condi, y=value, fill=variable)) +
geom_bar(stat="identity", position=position_dodge())+theme_bw() +
      theme(axis.text.x = element_text(size=8, angle = 90, hjust = 1),
            plot.title = element_text(size = 8, face = "bold"))

```

## 8.1 General DE Gene analysis

### Hierarchical Clustering of the union of DE genes 

```{r, echo=TRUE, message=FALSE, results='hide', fig.height=10, fig.width=12}
# the uDEG() function produces the union of the DE genes from the specified comparisons



allDEgenes <- uDEG(comparisons=c("COPD_2_vs_Control","COPD_3_4_vs_Control","COPD_2_vs_COPD_3_4"))
allDEgenes_symbol <- norm_anno[norm_anno$GENEID %in% allDEgenes,]$SYMBOL


```

### Hierarchical Clustering of genes of interest 

```{r, echo=TRUE, message=FALSE, results='hide', fig.width=12, fig.height=12}
# the uDEG() function produces the union of the DE genes from the specified comparisons

cutti = 20

macro_genes_Kevin <- read.csv("E:/Listen/SurfaceomeHuman&Mouse_2017_04_24_OP.txt",sep = "")
macro_genes_Kevin <- removedbatch_anno_log2[removedbatch_anno_log2$SYMBOL %in% macro_genes_Kevin$Human,]
macro_genes_Kevin <- macro_genes_Kevin[macro_genes_Kevin$SYMBOL %in% allDEgenes_symbol,]

dd1 = macro_genes_Kevin[order(apply(macro_genes_Kevin, 1, var),decreasing = T),]
macro_genes_Kevin <- head(dd1,20)
macro_genes_Kevin <- macro_genes_Kevin$GENEID
  
plotHeatmap(input = removedbatch_anno_log2,geneset = macro_genes_Kevin,
            title = "Heatmap of all differentially expressed genes",
            show_rownames = T,
            cluster_cols = TRUE)

norm_anno_Thomas <- head(dd1,cutti)
norm_anno_Thomas <- norm_anno_Thomas[,1:(ncol(norm_anno_Thomas)-3)]
norm_anno_Thomas <- norm_anno_Thomas[,-c(ncol(norm_anno_Thomas)-1)]
Dataset_1_symbol <- norm_anno_Thomas[!duplicated(norm_anno_Thomas[,ncol(norm_anno_Thomas)]), ]
Dataset_1_symbol <- Dataset_1_symbol[complete.cases(Dataset_1_symbol), ]
row.names(Dataset_1_symbol) <- Dataset_1_symbol[,ncol(norm_anno_Thomas)]
Dataset_1 <- Dataset_1_symbol[,c(-ncol(norm_anno_Thomas))]

colnames(Dataset_1) <- sample_table$condition

phenotype <- c(unique(names(Dataset_1)))
tmp <- as.data.frame(rowMeans(Dataset_1[,grep(phenotype[1], names(Dataset_1))]))
names(tmp)[length(tmp)] <- phenotype[1] 
df <- tmp
for(i in 2:length(phenotype)){
tmp <- as.data.frame(rowMeans(Dataset_1[,grep(phenotype[i], names(Dataset_1))]))
names(tmp)[length(tmp)] <- phenotype[i]
df <- merge(df, tmp, by = 0)
row.names(df) <- df$Row.names
df$Row.names <- NULL
}

df <- df[,c(2,1,3,4)]
pdf("E:/RNA-Seq/Wataru_COPD/Data/output/kallisto/Surfaceome.pdf", width=2, height=6)

pheatmap(df, 
         cluster_row = T,
         cluster_cols = T,
         scale = c("row"),
         #labels_col = c("COPD_2",  "Control" ,"COPD_3"  ,"COPD_4"),
         show_rownames = T,
         show_colnames = T,
         cellwidth = 15,
         cellheight = 12,
         main = c("Surfaceome"))
dev.off()

```
```{r, echo=TRUE, message=FALSE, results='hide', fig.width=12, fig.height=12}
# the uDEG() function produces the union of the DE genes from the specified comparisons


cutti = 20

macro_genes_Kevin <- read.csv("E:/Listen/human secretome.txt",sep = "")
macro_genes_Kevin <- removedbatch_anno_log2[removedbatch_anno_log2$SYMBOL %in% macro_genes_Kevin$A1AG1,]
macro_genes_Kevin <- macro_genes_Kevin[macro_genes_Kevin$SYMBOL %in% allDEgenes_symbol,]


dd1 = macro_genes_Kevin[order(apply(macro_genes_Kevin, 1, var),decreasing = T),]
macro_genes_Kevin <- head(dd1,20)
macro_genes_Kevin <- macro_genes_Kevin$GENEID
  
plotHeatmap(input = removedbatch_anno_log2,geneset = macro_genes_Kevin,
            title = "Heatmap of all differentially expressed genes",
            show_rownames = T,
            cluster_cols = TRUE)

norm_anno_Thomas <- head(dd1,cutti)
norm_anno_Thomas <- norm_anno_Thomas[,1:(ncol(norm_anno_Thomas)-3)]
norm_anno_Thomas <- norm_anno_Thomas[,-c(ncol(norm_anno_Thomas)-1)]
Dataset_1_symbol <- norm_anno_Thomas[!duplicated(norm_anno_Thomas[,ncol(norm_anno_Thomas)]), ]
Dataset_1_symbol <- Dataset_1_symbol[complete.cases(Dataset_1_symbol), ]
row.names(Dataset_1_symbol) <- Dataset_1_symbol[,ncol(norm_anno_Thomas)]
Dataset_1 <- Dataset_1_symbol[,c(-ncol(norm_anno_Thomas))]

colnames(Dataset_1) <- sample_table$condition

phenotype <- c(unique(names(Dataset_1)))
tmp <- as.data.frame(rowMeans(Dataset_1[,grep(phenotype[1], names(Dataset_1))]))
names(tmp)[length(tmp)] <- phenotype[1] 
df <- tmp
for(i in 2:length(phenotype)){
tmp <- as.data.frame(rowMeans(Dataset_1[,grep(phenotype[i], names(Dataset_1))]))
names(tmp)[length(tmp)] <- phenotype[i]
df <- merge(df, tmp, by = 0)
row.names(df) <- df$Row.names
df$Row.names <- NULL
}

df <- df[,c(2,1,3,4)]

pdf("E:/RNA-Seq/Wataru_COPD/Data/output/kallisto/Secretome.pdf", width=2, height=6)

pheatmap(df, 
         cluster_row = T,
         cluster_cols = T,
         scale = c("row"),
         #labels_col = c("COPD_2",  "Control" ,"COPD_3"  ,"COPD_4"),
         show_rownames = T,
         show_colnames = T,
         cellwidth = 15,
         cellheight = 12,
         main = c("Secretome"))

dev.off()
```
```{r, echo=TRUE, message=FALSE, results='hide', fig.width=12, fig.height=12}
# the uDEG() function produces the union of the DE genes from the specified comparisons


cutti = 20

macro_genes_Kevin <- read.delim("E:/Listen/epigenetic_modulators.txt")
macro_genes_Kevin <- removedbatch_anno_log2[removedbatch_anno_log2$SYMBOL %in% macro_genes_Kevin$gene,]
macro_genes_Kevin <- macro_genes_Kevin[macro_genes_Kevin$SYMBOL %in% allDEgenes_symbol,]

dd1 = macro_genes_Kevin[order(apply(macro_genes_Kevin, 1, var),decreasing = T),]
macro_genes_Kevin <- head(dd1,20)
macro_genes_Kevin <- macro_genes_Kevin$GENEID
  
plotHeatmap(input = removedbatch_anno_log2,geneset = macro_genes_Kevin,
            title = "Heatmap of all differentially expressed genes",
            show_rownames = T,
            cluster_cols = TRUE)

norm_anno_Thomas <- head(dd1,cutti)
norm_anno_Thomas <- norm_anno_Thomas[,1:(ncol(norm_anno_Thomas)-3)]
norm_anno_Thomas <- norm_anno_Thomas[,-c(ncol(norm_anno_Thomas)-1)]
Dataset_1_symbol <- norm_anno_Thomas[!duplicated(norm_anno_Thomas[,ncol(norm_anno_Thomas)]), ]
Dataset_1_symbol <- Dataset_1_symbol[complete.cases(Dataset_1_symbol), ]
row.names(Dataset_1_symbol) <- Dataset_1_symbol[,ncol(norm_anno_Thomas)]
Dataset_1 <- Dataset_1_symbol[,c(-ncol(norm_anno_Thomas))]

colnames(Dataset_1) <- sample_table$condition

phenotype <- c(unique(names(Dataset_1)))
tmp <- as.data.frame(rowMeans(Dataset_1[,grep(phenotype[1], names(Dataset_1))]))
names(tmp)[length(tmp)] <- phenotype[1] 
df <- tmp
for(i in 2:length(phenotype)){
tmp <- as.data.frame(rowMeans(Dataset_1[,grep(phenotype[i], names(Dataset_1))]))
names(tmp)[length(tmp)] <- phenotype[i]
df <- merge(df, tmp, by = 0)
row.names(df) <- df$Row.names
df$Row.names <- NULL
}

df <- df[,c(2,1,3,4)]
pdf("E:/RNA-Seq/Wataru_COPD/Data/output/kallisto/Epigenetic.pdf", width=2, height=6)

pheatmap(df, 
         cluster_row = T,
         cluster_cols = T,
         scale = c("row"),
         #labels_col = c("COPD_2",  "Control" ,"COPD_3"  ,"COPD_4"),
         show_rownames = T,
         show_colnames = T,
         cellwidth = 15,
         cellheight = 12,
         main = c("Epigenetic modulators"))
dev.off()



```

```{r, echo=TRUE, message=FALSE, results='hide', fig.width=12, fig.height=12}
# the uDEG() function produces the union of the DE genes from the specified comparisons


cutti = 20

macro_genes_Kevin <- read.delim("E:/Listen/TFcat.txt")
macro_genes_Kevin <- removedbatch_anno_log2[removedbatch_anno_log2$SYMBOL %in% macro_genes_Kevin$Human,]
macro_genes_Kevin <- macro_genes_Kevin[macro_genes_Kevin$SYMBOL %in% allDEgenes_symbol,]

dd1 = macro_genes_Kevin[order(apply(macro_genes_Kevin, 1, var),decreasing = T),]
macro_genes_Kevin <- head(dd1,20)
macro_genes_Kevin <- macro_genes_Kevin$GENEID
  
plotHeatmap(input = removedbatch_anno_log2,geneset = macro_genes_Kevin,
            title = "Heatmap of all differentially expressed genes",
            show_rownames = T,
            cluster_cols = TRUE)

norm_anno_Thomas <- head(dd1,cutti)
norm_anno_Thomas <- norm_anno_Thomas[,1:(ncol(norm_anno_Thomas)-3)]
norm_anno_Thomas <- norm_anno_Thomas[,-c(ncol(norm_anno_Thomas)-1)]
Dataset_1_symbol <- norm_anno_Thomas[!duplicated(norm_anno_Thomas[,ncol(norm_anno_Thomas)]), ]
Dataset_1_symbol <- Dataset_1_symbol[complete.cases(Dataset_1_symbol), ]
row.names(Dataset_1_symbol) <- Dataset_1_symbol[,ncol(norm_anno_Thomas)]
Dataset_1 <- Dataset_1_symbol[,c(-ncol(norm_anno_Thomas))]

colnames(Dataset_1) <- sample_table$condition

phenotype <- c(unique(names(Dataset_1)))
tmp <- as.data.frame(rowMeans(Dataset_1[,grep(phenotype[1], names(Dataset_1))]))
names(tmp)[length(tmp)] <- phenotype[1] 
df <- tmp
for(i in 2:length(phenotype)){
tmp <- as.data.frame(rowMeans(Dataset_1[,grep(phenotype[i], names(Dataset_1))]))
names(tmp)[length(tmp)] <- phenotype[i]
df <- merge(df, tmp, by = 0)
row.names(df) <- df$Row.names
df$Row.names <- NULL
}

df <- df[,c(2,1,3,4)]
pdf("E:/RNA-Seq/Wataru_COPD/Data/output/kallisto/TF.pdf", width=2, height=6)

pheatmap(df, 
         cluster_row = T,
         cluster_cols = T,
         scale = c("row"),
         #labels_col = c("COPD_2",  "Control" ,"COPD_3"  ,"COPD_4"),
         show_rownames = T,
         show_colnames = T,
         cellwidth = 15,
         cellheight = 12,
         main = c("TF"))
dev.off()

```


### GSEA across comparisons

Define universe and gene sets for subsequent GSEA analyses.

```{r}
# define universe
universe <- as.character(norm_anno$SYMBOL)
# change symbols to ENTREZ IDs (necessary for ClusterProfiler)
universe_Entrez <- bitr(universe, 
                        fromType="SYMBOL", 
                        toType="ENTREZID", 
                        OrgDb="org.Hs.eg.db")$ENTREZID


```

Next, we perform functional enrichment analysis based on Gene ontology and KEGG pathway enrichment across all comparisons tested to check for overlap in functional indications of the differentially regulated genes. 

```{r, fig.height=8, fig.width=12, warnings=FALSE, message=FALSE}
DEcompare <- compareGSEA(comparisons = c("COPD_2_vs_Control","COPD_3_4_vs_Control","COPD_2_vs_COPD_3_4"),
                         organism = "human",
                         GeneSets = c("GO","KEGG"),
                         pCorrection = "none", 
                         pvalueCutoff = 0.05,
                         qvalueCutoff = 0.1,
                         showMax = 5, 
                         ontology = "BP")

DEcompare$GOplot
DEcompare$KEGGplot



```

### Volcano Plots

A volcano plot is a type of scatter-plot that is used to quickly identify changes in large data sets composed of replicate data. It plots significance versus fold-change on the y and x axes, respectively. 

```{r}
# Plot Volcano Plot
  vol_1 <- plotVolcano(comparison= "COPD_2_vs_Control",
              labelnum=10)
  vol_2 <- plotVolcano(comparison= "COPD_3_4_vs_Control",
              labelnum=10)
  vol_3 <- plotVolcano(comparison= "COPD_2_vs_COPD_3_4",
              labelnum=10)
  
  grid.arrange(arrangeGrob(vol_1,vol_2,vol_3, nrow=1))

  
```
